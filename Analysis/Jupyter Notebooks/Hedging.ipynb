{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hedging classification\n",
    "\n",
    "This notebooks will analyze hedging patterns in the collected articles corpus. \n",
    "\n",
    "1. Look at distributions, frequencies of hedge words in the documents\n",
    "2. Train semisupervised classification algorithm on individual sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just text reading/cleaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from read_json import JsonHelpers\n",
    "import analysis_helper_functions as helpers\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import clean_txt as clean\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if sys.platform == \"linux\":\n",
    "    studies_path = \"/home/wiktor/git/MasterThesis/Literature/Competition_Studies_Database/studies.json\"\n",
    "    authors_path = \"/home/wiktor/git/MasterThesis/Literature/Competition_Studies_Database/authors.json\"\n",
    "    studies_location = \"/home/wiktor/Dropbox/Git/MasterThesis/Literature/Competition_Studies_Database/\"\n",
    "else:    \n",
    "    studies_path = \"/Users/Wiktor/Dropbox/Git/MasterThesis/Literature/Competition_Studies_Database/studies.json\"\n",
    "    authors_path = \"/Users/Wiktor/Dropbox/Git/MasterThesis/Literature/Competition_Studies_Database/authors.json\"\n",
    "    studies_location = \"/Users/Wiktor/Dropbox/Git/MasterThesis/Literature/Competition_Studies_Database/\"\n",
    "\n",
    "# Documents collection with labels\n",
    "df_documents = helpers.read_txt_studies(studies_location)\n",
    "\n",
    "# List of all documents as strings\n",
    "documents = df_documents['document'].tolist()\n",
    "\n",
    "# List of labels\n",
    "article_labels = df_documents['label'].tolist()\n",
    "\n",
    "# CB label\n",
    "cb = JsonHelpers().central_bank_paper_label()\n",
    "\n",
    "context_stopwords = ['panzar', 'rosse','panzarrosse', 'rossepanzar', 'prh','journal', 'sciencedirect',\n",
    "                     'banking', 'rosse–panzar', 'vol', 'department', 'university', 'school', 'economics',\n",
    "                     'business', 'email', 'cid', 'bank', 'banking', 'asset', 'assets', 'revenue', 'total', \n",
    "                     'hstatistic', 'h-statistic', 'competition', 'finance', 'banks']\n",
    "# List of tokenized documents\n",
    "texts_token_clean = [clean.normalize(text, context_stopwords, exclude_stops=False) for text in documents]\n",
    "\n",
    "# List of clean strings\n",
    "texts_str_clean = helpers.convert_list(texts_token_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-be6d99ad64a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking reported database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpaper_database\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_documents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([^.]*?database[^.]*\\.)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2510\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-be6d99ad64a1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking reported database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpaper_database\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_documents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([^.]*?database[^.]*\\.)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Checking reported database\n",
    "paper_database = df_documents['document'].apply(lambda x: re.findall(r\"([^.]*?database[^.]*\\.)\", x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertanity index per paper\n",
    "\n",
    "Using hedge words I calculate uncertanity index: number of hedge words in the document, divided by number of words in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>cb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p032</td>\n",
       "      <td>0.089467</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p048</td>\n",
       "      <td>0.082132</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p074</td>\n",
       "      <td>0.077574</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p053</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p070</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p003</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p057</td>\n",
       "      <td>0.065937</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p034</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p014</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p051</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p073</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p005</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>p019</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>p065</td>\n",
       "      <td>0.058723</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p054</td>\n",
       "      <td>0.058021</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p071</td>\n",
       "      <td>0.057450</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p001</td>\n",
       "      <td>0.057362</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p033</td>\n",
       "      <td>0.057119</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>p064</td>\n",
       "      <td>0.056907</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>p024</td>\n",
       "      <td>0.056893</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p045</td>\n",
       "      <td>0.056235</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>p020</td>\n",
       "      <td>0.055409</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>p010</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>p030</td>\n",
       "      <td>0.054017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>p012</td>\n",
       "      <td>0.053696</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>p062</td>\n",
       "      <td>0.053408</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>p046</td>\n",
       "      <td>0.053216</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p044</td>\n",
       "      <td>0.052822</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>p068</td>\n",
       "      <td>0.052392</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>p063</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>p040</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>p008</td>\n",
       "      <td>0.049850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>p026</td>\n",
       "      <td>0.049391</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>p021</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>p018</td>\n",
       "      <td>0.048830</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>p055</td>\n",
       "      <td>0.047481</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>p052</td>\n",
       "      <td>0.047365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>p015</td>\n",
       "      <td>0.047349</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>p011</td>\n",
       "      <td>0.047323</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>p027</td>\n",
       "      <td>0.047280</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>p002</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>p029</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>p023</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>p025</td>\n",
       "      <td>0.044986</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>p058</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>p009</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>p038</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>p013</td>\n",
       "      <td>0.043248</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>p043</td>\n",
       "      <td>0.042368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>p016</td>\n",
       "      <td>0.039640</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>p047</td>\n",
       "      <td>0.037596</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>p039</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>p036</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>p031</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>p022</td>\n",
       "      <td>0.034218</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>p041</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>p004</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>p069</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>p067</td>\n",
       "      <td>0.028608</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>p037</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1     cb\n",
       "0   p032  0.089467   True\n",
       "1   p048  0.082132  False\n",
       "2   p074  0.077574  False\n",
       "3   p053  0.073553   True\n",
       "4   p070  0.068966  False\n",
       "5   p003  0.066594  False\n",
       "6   p057  0.065937  False\n",
       "7   p034  0.064996  False\n",
       "8   p014  0.063074  False\n",
       "9   p051  0.061458  False\n",
       "10  p073  0.060942  False\n",
       "11  p005  0.060382  False\n",
       "12  p019  0.059615  False\n",
       "13  p065  0.058723   True\n",
       "14  p054  0.058021   True\n",
       "15  p071  0.057450  False\n",
       "16  p001  0.057362   True\n",
       "17  p033  0.057119  False\n",
       "18  p064  0.056907  False\n",
       "19  p024  0.056893   True\n",
       "20  p045  0.056235  False\n",
       "21  p020  0.055409  False\n",
       "22  p010  0.054435  False\n",
       "23  p030  0.054017  False\n",
       "24  p012  0.053696  False\n",
       "25  p062  0.053408  False\n",
       "26  p046  0.053216  False\n",
       "27  p044  0.052822  False\n",
       "28  p068  0.052392  False\n",
       "29  p063  0.051852  False\n",
       "..   ...       ...    ...\n",
       "37  p040  0.049898  False\n",
       "38  p008  0.049850   True\n",
       "39  p026  0.049391  False\n",
       "40  p021  0.049267  False\n",
       "41  p018  0.048830  False\n",
       "42  p055  0.047481  False\n",
       "43  p052  0.047365   True\n",
       "44  p015  0.047349  False\n",
       "45  p011  0.047323  False\n",
       "46  p027  0.047280  False\n",
       "47  p002  0.045825  False\n",
       "48  p029  0.045794  False\n",
       "49  p023  0.045343   True\n",
       "50  p025  0.044986   True\n",
       "51  p058  0.044118  False\n",
       "52  p009  0.044008  False\n",
       "53  p038  0.043304  False\n",
       "54  p013  0.043248  False\n",
       "55  p043  0.042368  False\n",
       "56  p016  0.039640  False\n",
       "57  p047  0.037596  False\n",
       "58  p039  0.036176  False\n",
       "59  p036  0.035672   True\n",
       "60  p031  0.034222   True\n",
       "61  p022  0.034218  False\n",
       "62  p041  0.033079   True\n",
       "63  p004  0.030500  False\n",
       "64  p069  0.030435  False\n",
       "65  p067  0.028608  False\n",
       "66  p037  0.028284   True\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open file with hedge words\n",
    "hedge_words = []\n",
    "with open('hedge_words.txt', 'rt') as file:\n",
    "    for line in file:\n",
    "        if '#' not in line:\n",
    "            hedge_words.append(line.replace('\\n', ''))\n",
    "    \n",
    "def uncertainty_index(documents, labels, hedge_words):\n",
    "    \"\"\"\n",
    "    Calculate uncertanity index for all all collected papers\n",
    "    \n",
    "    number of hedge words seen / total number of words in text\n",
    "    \"\"\"\n",
    "\n",
    "    hedge_score = []\n",
    "    for document, label in zip(documents, labels):\n",
    "        keys_count = [document.count(key) for key in hedge_words]\n",
    "        hedge_score.append((label, sum(keys_count)/len(re.findall(r'\\w+', document))))\n",
    "\n",
    "    return hedge_score\n",
    "\n",
    "\n",
    "# Undertanity index per document table\n",
    "undertanity_df = pd.DataFrame(uncertainty_index(texts_str_clean, article_labels, hedge_words))\n",
    "undertanity_df['cb'] = undertanity_df[0].isin(cb)\n",
    "sorted_undertanity_df = undertanity_df.sort_values(by=1, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Uncertanity Rank of CB papers \n",
    "uncertanity_df_cb = sorted_undertanity_df[sorted_undertanity_df['cb'] == True].reset_index()\n",
    "uncertanity_df_cb.drop(['cb'], axis=1, inplace=True)\n",
    "uncertanity_df_cb.columns = ['rank', 'article label', 'uncertanity score']\n",
    "uncertanity_df_cb['rank'] = uncertanity_df_cb['rank'] + 1\n",
    "\n",
    "# Saving table\n",
    "uncertanity_df_cb.to_excel('uncertanity_score_cb.xlsx', index=False)\n",
    "\n",
    "# Uncertanity Rank of NCB papers \n",
    "uncertanity_df_ncb = sorted_undertanity_df[sorted_undertanity_df['cb'] == False].reset_index()\n",
    "uncertanity_df_ncb.drop(['cb'], axis=1, inplace=True)\n",
    "uncertanity_df_ncb.columns = ['rank', 'article label', 'uncertanity score']\n",
    "uncertanity_df_ncb['rank'] = uncertanity_df_ncb['rank'] + 1\n",
    "\n",
    "# Saving table\n",
    "uncertanity_df_ncb.to_excel('uncertanity_score_ncb.xlsx', index=False)\n",
    "\n",
    "sorted_undertanity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent used hedge words accross all papers and groups split\n",
    "\n",
    "http://web.informatik.uni-mannheim.de/ponzetto/pubs/stajner17a\n",
    "\n",
    "The following are considered hedge instances **(Medlock, Briscoe)**:\n",
    "- data_Set to train: https://sraf.nd.edu/textual-analysis/resources/#LM%20Sentiment%20Word%20Lists (MacDonald word list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all texts\n",
    "single_corpa =  ' '.join(texts_str_clean)\n",
    "\n",
    "# Hedge words distribution accross all texts\n",
    "full_popular_hedge = []\n",
    "for key in hedge_words:\n",
    "    full_popular_hedge.append((key, single_corpa.count(key)))\n",
    "    \n",
    "# Data Frame with most popular hedge words\n",
    "all_hedge = pd.DataFrame(full_popular_hedge).sort_values(by=1, ascending=False)\n",
    "\n",
    "\n",
    "ncb_texts_clean = []\n",
    "cb_texts_clean = []\n",
    "for text, label in zip(texts_str_clean, article_labels):\n",
    "    if label in cb:\n",
    "        cb_texts_clean.append(text)\n",
    "    else:\n",
    "        ncb_texts_clean.append(text)\n",
    "        \n",
    "# Distributions of hedge words accross two groups of papers        \n",
    "ncb_single_text_clean = ' '.join(ncb_texts_clean)\n",
    "cb_single_text_clean = ' '.join(cb_texts_clean)\n",
    "\n",
    "cb_popular_hedge = []\n",
    "ncb_popular_hedge = []\n",
    "\n",
    "for key in hedge_words:\n",
    "    cb_popular_hedge.append((key, cb_single_text_clean.count(key), cb_single_text_clean.count(key)/len(re.findall(r'\\w+', cb_single_text_clean))))\n",
    "    ncb_popular_hedge.append((key, ncb_single_text_clean.count(key), ncb_single_text_clean.count(key)/len(re.findall(r'\\w+', ncb_single_text_clean))))\n",
    "    \n",
    "cb_hedge = pd.DataFrame(cb_popular_hedge).sort_values(by=1, ascending=False)\n",
    "ncb_hedge = pd.DataFrame(ncb_popular_hedge).sort_values(by=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>differ</td>\n",
       "      <td>780</td>\n",
       "      <td>0.004046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>depend</td>\n",
       "      <td>660</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>indicate</td>\n",
       "      <td>531</td>\n",
       "      <td>0.002755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>risk</td>\n",
       "      <td>482</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>some</td>\n",
       "      <td>428</td>\n",
       "      <td>0.002220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>suggest</td>\n",
       "      <td>409</td>\n",
       "      <td>0.002122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>find</td>\n",
       "      <td>391</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>most</td>\n",
       "      <td>343</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>consider</td>\n",
       "      <td>330</td>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>many</td>\n",
       "      <td>246</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>would</td>\n",
       "      <td>238</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>like</td>\n",
       "      <td>223</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>assume</td>\n",
       "      <td>210</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>could</td>\n",
       "      <td>181</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tend</td>\n",
       "      <td>179</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>variation</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>assumption</td>\n",
       "      <td>159</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>seem</td>\n",
       "      <td>157</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>might</td>\n",
       "      <td>144</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>potential</td>\n",
       "      <td>140</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>read</td>\n",
       "      <td>137</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>possible</td>\n",
       "      <td>137</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>appear</td>\n",
       "      <td>133</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>overall</td>\n",
       "      <td>131</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>rather</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>several</td>\n",
       "      <td>123</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>random</td>\n",
       "      <td>102</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>much</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>vary</td>\n",
       "      <td>94</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>likely</td>\n",
       "      <td>94</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>looks like</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>more or less</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>appearing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>appear to be</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>my impression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>my thinking is</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>my understanding is</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>nonassessable</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>obtainable</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>anticipations</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>plausibly</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>anticipating</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>anticipates</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>precautionary</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>probabilistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>precautions</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abeyance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>predictability</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>predicting</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>predictor</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>predictors</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>predicts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>preliminarily</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>presumable</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>presumed</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>presumes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>presuming</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>presumptions</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>presumptuously</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a bit</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0    1         2\n",
       "100               differ  780  0.004046\n",
       "86                depend  660  0.003424\n",
       "160             indicate  531  0.002755\n",
       "277                 risk  482  0.002500\n",
       "298                 some  428  0.002220\n",
       "321              suggest  409  0.002122\n",
       "118                 find  391  0.002028\n",
       "180                 most  343  0.001779\n",
       "72              consider  330  0.001712\n",
       "175                 many  246  0.001276\n",
       "420                would  238  0.001235\n",
       "168                 like  223  0.001157\n",
       "42                assume  210  0.001089\n",
       "81                 could  181  0.000939\n",
       "332                 tend  179  0.000929\n",
       "409            variation  177  0.000918\n",
       "46            assumption  159  0.000825\n",
       "289                 seem  157  0.000814\n",
       "178                might  144  0.000747\n",
       "203            potential  140  0.000726\n",
       "249                 read  137  0.000711\n",
       "201             possible  137  0.000711\n",
       "28                appear  133  0.000690\n",
       "194              overall  131  0.000680\n",
       "248               rather  128  0.000664\n",
       "295              several  123  0.000638\n",
       "239               random  102  0.000529\n",
       "182                 much   99  0.000514\n",
       "413                 vary   94  0.000488\n",
       "170               likely   94  0.000488\n",
       "..                   ...  ...       ...\n",
       "173           looks like    0  0.000000\n",
       "179         more or less    0  0.000000\n",
       "31             appearing    0  0.000000\n",
       "29          appear to be    0  0.000000\n",
       "184        my impression    0  0.000000\n",
       "185       my thinking is    0  0.000000\n",
       "186  my understanding is    0  0.000000\n",
       "189        nonassessable    0  0.000000\n",
       "190           obtainable    0  0.000000\n",
       "25         anticipations    0  0.000000\n",
       "198            plausibly    0  0.000000\n",
       "23          anticipating    0  0.000000\n",
       "22           anticipates    0  0.000000\n",
       "208        precautionary    0  0.000000\n",
       "231        probabilistic    0  0.000000\n",
       "209          precautions    0  0.000000\n",
       "1               abeyance    0  0.000000\n",
       "211       predictability    0  0.000000\n",
       "213           predicting    0  0.000000\n",
       "216            predictor    0  0.000000\n",
       "217           predictors    0  0.000000\n",
       "218             predicts    0  0.000000\n",
       "219        preliminarily    0  0.000000\n",
       "221           presumable    0  0.000000\n",
       "224             presumed    0  0.000000\n",
       "225             presumes    0  0.000000\n",
       "226            presuming    0  0.000000\n",
       "228         presumptions    0  0.000000\n",
       "229       presumptuously    0  0.000000\n",
       "0                 \n",
       "a bit    0  0.000000\n",
       "\n",
       "[421 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All papers popular hedge\n",
    "all_hedge\n",
    "\n",
    "# CB papers popular hedge\n",
    "cb_hedge\n",
    "\n",
    "# NCB papers popular hedge\n",
    "ncb_hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing words\n",
    "testing_words = []\n",
    "\n",
    "full_popular_testing = []\n",
    "cb_popular_testing = []\n",
    "ncb_popular_testing = []\n",
    "\n",
    "with open('hypothesis_testing_words.txt', 'rt') as file:\n",
    "    for line in file:\n",
    "        if '#' not in line:\n",
    "            testing_words.append(line.replace('\\n', ''))\n",
    "\n",
    "for key in testing_words:\n",
    "    cb_popular_testing.append((key, cb_single_text_clean.count(key), cb_single_text_clean.count(key)/len(re.findall(r'\\w+', cb_single_text_clean))))\n",
    "    ncb_popular_testing.append((key, ncb_single_text_clean.count(key), ncb_single_text_clean.count(key)/len(re.findall(r'\\w+',ncb_single_text_clean))))\n",
    "    full_popular_testing.append((key, single_corpa.count(key), single_corpa.count(key)/len(re.findall(r'\\w+',single_corpa))))\n",
    "\n",
    "\n",
    "cb_testing = pd.DataFrame(cb_popular_testing).sort_values(by=2, ascending=False)\n",
    "ncb_testing = pd.DataFrame(ncb_popular_testing).sort_values(by=2, ascending=False)\n",
    "all_testing = pd.DataFrame(full_popular_testing).sort_values(by=2, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reject</td>\n",
       "      <td>447</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hypothesis</td>\n",
       "      <td>376</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>significant</td>\n",
       "      <td>345</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>error</td>\n",
       "      <td>213</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alternative</td>\n",
       "      <td>122</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>null hypothesis</td>\n",
       "      <td>105</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pvalue</td>\n",
       "      <td>89</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>significantly</td>\n",
       "      <td>84</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>significance level</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reject null</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>confidence interval</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>confidence level</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>confidence intervals</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lower bound</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>upper bound</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alternative hypothesis</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p-value</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>type i error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>type ii error</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fail to reject</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0    1         2\n",
       "2                   reject  447  0.002319\n",
       "3               hypothesis  376  0.001951\n",
       "7              significant  345  0.001790\n",
       "19                   error  213  0.001105\n",
       "6              alternative  122  0.000633\n",
       "4          null hypothesis  105  0.000545\n",
       "15                  pvalue   89  0.000462\n",
       "8            significantly   84  0.000436\n",
       "9       significance level   38  0.000197\n",
       "1              reject null   37  0.000192\n",
       "11     confidence interval    6  0.000031\n",
       "10        confidence level    4  0.000021\n",
       "12    confidence intervals    1  0.000005\n",
       "13             lower bound    0  0.000000\n",
       "14             upper bound    0  0.000000\n",
       "5   alternative hypothesis    0  0.000000\n",
       "16                 p-value    0  0.000000\n",
       "17            type i error    0  0.000000\n",
       "18           type ii error    0  0.000000\n",
       "0           fail to reject    0  0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All papers popular hedge\n",
    "all_testing\n",
    "\n",
    "# CB papers popular hedge\n",
    "cb_testing\n",
    "\n",
    "# NCB papers popular hedge\n",
    "ncb_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence uncertanity/vagueness analysis\n",
    "\n",
    "To train supervised classifiers, we first transformed the sentences from the articles into a vector of numbers. We explored vector representations such as TF-IDF weighted vectors.\n",
    "\n",
    "After having this vector representations of the text we can train supervised classifiers to predict the “uncertanity” of the sentence.\n",
    "\n",
    "http://web.informatik.uni-mannheim.de/ponzetto/pubs/stajner17a\n",
    "\n",
    "The following are considered hedge instances **(Medlock, Briscoe)**:\n",
    "- data_Set to train: https://sraf.nd.edu/textual-analysis/resources/#LM%20Sentiment%20Word%20Lists (MacDonald word list) \n",
    "\n",
    "\n",
    "The Wikipedia training set (CoNLL-2010 shared task, v2.0,\n",
    "task1) was used as the training set for all our experiments,\n",
    "as it is the largest existing general-domain dataset annotated\n",
    "for speculation. It contains a total of 11111 sentences, out of\n",
    "which 2346 were marked as speculative (uncertain). A few\n",
    "examples from this dataset are presented in Table V.\n",
    "\n",
    "use :  Task1 wikipedia other variant (sentence tags in separate lines)\n",
    "\n",
    "T. Loughran and B. McDonald, “When is a Liability not a Liability?\n",
    "Textual Analysis, Dictionaries, and 10-Ks,” Journal of Finance, 2010.\n",
    "\n",
    "\n",
    "The feature\n",
    "set consisted of frequencies of each speculation trigger plus an additional feature (the total number of triggers found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with text and corresponding label\n",
    "sentence_df = pd.concat([pd.Series(texts_str_clean), pd.Series(article_labels)], ignore_index=True, axis=1)\n",
    "\n",
    "# Label columns\n",
    "sentence_df.columns = ['sentence', 'label']\n",
    "\n",
    "# Expand columns by splitting text into sentences on '.'\n",
    "sentence_df = sentence_df.set_index(sentence_df.columns.drop('sentence',1).tolist())\\\n",
    "                                                                          .sentence.str.split('.', expand=True)\\\n",
    "                                                                          .stack()\\\n",
    "                                                                          .reset_index()\\\n",
    "                                                                          .rename(columns={0:'sentence'})\\\n",
    "                                                                          .loc[:, sentence_df.columns]\n",
    "\n",
    "# Drop sentences with les than 20 characters\n",
    "sentence_df = sentence_df[sentence_df['sentence'].apply(lambda x: len(x)>20)]\n",
    "\n",
    "# Count number of words per sentence\n",
    "sentence_df['no_words'] = sentence_df['sentence'].apply(lambda x: len(re.findall(r'\\w+', x)))\n",
    "\n",
    "# Assign \"uncertanity category\"\n",
    "sentence_df['uncertain'] = sentence_df['sentence'].str.contains('|'.join(hedge_words))\n",
    "\n",
    "# Convert boolean to integer\n",
    "sentence_df['uncertain'] = sentence_df['uncertain'].apply(lambda x: x*1)\n",
    "\n",
    "sentence_df['cb'] = sentence_df['label'].isin(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF setup\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(sentence_df['sentence'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf,\n",
    "                                                    sentence_df['uncertain'], random_state = 0, test_size=0.3)\n",
    "\n",
    "# Random forest with 100 trees\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.98      0.88      2673\n",
      "          1       0.97      0.72      0.83      2396\n",
      "\n",
      "avg / total       0.88      0.86      0.85      5069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(clf.predict(X_test), y_test)\n",
    "\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2623</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>674</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2623    50\n",
       "1   674  1722"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tfidf_list = []\n",
    "\n",
    "# for i in X_tfidf:\n",
    "#     tfidf_list.append(clf.predict(i)[0])\n",
    "    \n",
    "# # Make full sample (article) prediction, classifier tesed on the sample\n",
    "# sentence_df['prediction_on_sample'] = tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_cb = sentence_df[sentence_df['label'].isin(cb)]\n",
    "sentence_ncb = sentence_df[~sentence_df['label'].isin(cb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using wikipedia sentence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data, 22222 sentences\n",
    "wiki_data = pd.read_csv('wiki_data_clean.csv')\n",
    "\n",
    "# Transform string certanity variable into dummy \n",
    "wiki_data['uncertanity_dummy'] = wiki_data['certanity'].str.get_dummies()['uncertain']\n",
    "\n",
    "# Dropping sentences that were NaN (not string)\n",
    "wiki_data = wiki_data[wiki_data['sentence'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Selecting only strings with more than 20 characters (removing single words), 18744 remain\n",
    "wiki_data = wiki_data[wiki_data['sentence'].apply(lambda x: len(x) > 20)]\n",
    "\n",
    "# Transform data into TFIDF, adding data from the articles to have appropreate number of features \n",
    "# first 18744 rows are wiki, remainder articles\n",
    "wiki_tfidf = tfidf.fit_transform(pd.concat([wiki_data['sentence'], sentence_df['sentence']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training random forest on wikipedia data\n",
    "rf_wiki = RandomForestClassifier(n_estimators=100, n_jobs=-1).fit(wiki_tfidf[:18744],\n",
    "                                                                   wiki_data['uncertanity_dummy'])\n",
    "\n",
    "nb_wiki = MultinomialNB().fit(wiki_tfidf[:18744],\n",
    "                              wiki_data['uncertanity_dummy'])\n",
    "\n",
    "svc_wiki = SVC(kernel='linear').fit(wiki_tfidf[:18744],\n",
    "                     wiki_data['uncertanity_dummy'])\n",
    "\n",
    "# Predict uncertanity based on article data using RF\n",
    "rf_wiki_prediction = rf_wiki.predict(wiki_tfidf[18744:])\n",
    "\n",
    "# Predict uncertanity based on article data using NB\n",
    "nb_wiki_prediction = nb_wiki.predict(wiki_tfidf[18744:])\n",
    "\n",
    "# Predict uncertanity based on article data using SVM\n",
    "svc_wiki_prediction = svc_wiki.predict(wiki_tfidf[18744:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030495654972642422"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems: unsupported words, seen in article but not in wiki\n",
    "# no proper way to measure the prediction\n",
    "\n",
    "sentence_df['rf_wiki_predicion'] = rf_wiki_prediction \n",
    "sentence_df['nb_wiki_predicion'] = nb_wiki_prediction \n",
    "sentence_df['svc_wiki_prediction'] = svc_wiki_prediction \n",
    "\n",
    "\n",
    "\n",
    "# Calculation fraction of sentences considered to be uncertain within each group RF\n",
    "sentence_df[sentence_df['label'].isin(cb)]['rf_wiki_predicion'].sum()/len(sentence_df[sentence_df['label'].isin(cb)]['rf_wiki_predicion'])\n",
    "sentence_df[~sentence_df['label'].isin(cb)]['rf_wiki_predicion'].sum()/len(sentence_df[~sentence_df['label'].isin(cb)]['rf_wiki_predicion'])\n",
    "\n",
    "# Calculation fraction of sentences considered to be uncertain within each group SVM\n",
    "sentence_df[sentence_df['label'].isin(cb)]['svc_wiki_prediction'].sum()/len(sentence_df[sentence_df['label'].isin(cb)]['svc_wiki_prediction'])\n",
    "sentence_df[~sentence_df['label'].isin(cb)]['svc_wiki_prediction'].sum()/len(sentence_df[~sentence_df['label'].isin(cb)]['svc_wiki_prediction'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RF classified 508 as uncertain out of 16903\n",
    "    - 0.0281 of all CB sentences are considered to be uncertain\n",
    "    - 0.0305 of all NCB sentence are considered to be uncertain\n",
    "\n",
    "2. SVM classified 526 as uncertain out of 16903\n",
    "    - 0.0372 of all CB sentences are considered to be uncertain\n",
    "    - 0.0297 of all NCB sentence are considered to be uncertain\n",
    "\n",
    "e.g \"The estimation results for Specification II lead to different and\n",
    "possibly misleading inferences about the nature of competition, if\n",
    "they are interpreted using the same criteria regardless of the inclusion\n",
    "of ln(yi,t) as an additional control variable in Specification II.\"\n",
    "\n",
    "CB:\n",
    "\"Our results suggest that\n",
    "European banks were operating under conditions of monopolistic competition and\n",
    "that bank interest revenues in the 10 new EU member states was earned under\n",
    "conditions of higher competition than those that existed in the old EU banking\n",
    "countries\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>svc_wiki_prediction</th>\n",
       "      <th>sentence</th>\n",
       "      <th>uncertan_sentence_index</th>\n",
       "      <th>cb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p026</td>\n",
       "      <td>15</td>\n",
       "      <td>174</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p032</td>\n",
       "      <td>25</td>\n",
       "      <td>302</td>\n",
       "      <td>0.082781</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p059</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p048</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p074</td>\n",
       "      <td>20</td>\n",
       "      <td>344</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p062</td>\n",
       "      <td>15</td>\n",
       "      <td>259</td>\n",
       "      <td>0.057915</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p034</td>\n",
       "      <td>10</td>\n",
       "      <td>181</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p057</td>\n",
       "      <td>10</td>\n",
       "      <td>183</td>\n",
       "      <td>0.054645</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p065</td>\n",
       "      <td>19</td>\n",
       "      <td>355</td>\n",
       "      <td>0.053521</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p051</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p007</td>\n",
       "      <td>9</td>\n",
       "      <td>175</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p029</td>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>p011</td>\n",
       "      <td>18</td>\n",
       "      <td>355</td>\n",
       "      <td>0.050704</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>p020</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p009</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p045</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p067</td>\n",
       "      <td>7</td>\n",
       "      <td>158</td>\n",
       "      <td>0.044304</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p027</td>\n",
       "      <td>7</td>\n",
       "      <td>171</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>p018</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>p053</td>\n",
       "      <td>14</td>\n",
       "      <td>358</td>\n",
       "      <td>0.039106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p063</td>\n",
       "      <td>13</td>\n",
       "      <td>337</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>p069</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>p003</td>\n",
       "      <td>8</td>\n",
       "      <td>235</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>p023</td>\n",
       "      <td>7</td>\n",
       "      <td>207</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>p042</td>\n",
       "      <td>6</td>\n",
       "      <td>181</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>p041</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>p068</td>\n",
       "      <td>9</td>\n",
       "      <td>284</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p031</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>p061</td>\n",
       "      <td>7</td>\n",
       "      <td>227</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>p073</td>\n",
       "      <td>10</td>\n",
       "      <td>326</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>p010</td>\n",
       "      <td>9</td>\n",
       "      <td>346</td>\n",
       "      <td>0.026012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>p025</td>\n",
       "      <td>7</td>\n",
       "      <td>275</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>p054</td>\n",
       "      <td>6</td>\n",
       "      <td>238</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>p016</td>\n",
       "      <td>5</td>\n",
       "      <td>201</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>p015</td>\n",
       "      <td>5</td>\n",
       "      <td>203</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>p038</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>p033</td>\n",
       "      <td>13</td>\n",
       "      <td>533</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>p008</td>\n",
       "      <td>10</td>\n",
       "      <td>419</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>p066</td>\n",
       "      <td>5</td>\n",
       "      <td>213</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>p024</td>\n",
       "      <td>6</td>\n",
       "      <td>259</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>p002</td>\n",
       "      <td>7</td>\n",
       "      <td>313</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>p044</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>p013</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>p036</td>\n",
       "      <td>17</td>\n",
       "      <td>772</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>p030</td>\n",
       "      <td>4</td>\n",
       "      <td>182</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>p012</td>\n",
       "      <td>6</td>\n",
       "      <td>278</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>p005</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>p052</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>p070</td>\n",
       "      <td>5</td>\n",
       "      <td>257</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>p022</td>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>p040</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>p021</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>p043</td>\n",
       "      <td>4</td>\n",
       "      <td>246</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>p019</td>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>p014</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>p037</td>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>p004</td>\n",
       "      <td>5</td>\n",
       "      <td>562</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>p035</td>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>p064</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>p046</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  svc_wiki_prediction  sentence  uncertan_sentence_index     cb\n",
       "0   p026                   15       174                 0.086207  False\n",
       "1   p032                   25       302                 0.082781   True\n",
       "2   p059                    5        80                 0.062500   True\n",
       "3   p048                   16       260                 0.061538  False\n",
       "4   p074                   20       344                 0.058140  False\n",
       "5   p062                   15       259                 0.057915  False\n",
       "6   p034                   10       181                 0.055249  False\n",
       "7   p057                   10       183                 0.054645  False\n",
       "8   p065                   19       355                 0.053521   True\n",
       "9   p051                    6       114                 0.052632  False\n",
       "10  p007                    9       175                 0.051429  False\n",
       "11  p029                    6       117                 0.051282  False\n",
       "12  p011                   18       355                 0.050704  False\n",
       "13  p020                    5       100                 0.050000  False\n",
       "14  p009                    9       200                 0.045000  False\n",
       "15  p045                   10       225                 0.044444  False\n",
       "16  p067                    7       158                 0.044304  False\n",
       "17  p027                    7       171                 0.040936  False\n",
       "18  p018                    5       126                 0.039683  False\n",
       "19  p053                   14       358                 0.039106   True\n",
       "20  p063                   13       337                 0.038576  False\n",
       "21  p069                    4       108                 0.037037  False\n",
       "22  p003                    8       235                 0.034043  False\n",
       "23  p023                    7       207                 0.033816   True\n",
       "24  p042                    6       181                 0.033149  False\n",
       "25  p041                    4       122                 0.032787   True\n",
       "26  p068                    9       284                 0.031690  False\n",
       "27  p031                    8       256                 0.031250   True\n",
       "28  p061                    7       227                 0.030837  False\n",
       "29  p073                   10       326                 0.030675  False\n",
       "..   ...                  ...       ...                      ...    ...\n",
       "37  p010                    9       346                 0.026012  False\n",
       "38  p025                    7       275                 0.025455   True\n",
       "39  p054                    6       238                 0.025210   True\n",
       "40  p016                    5       201                 0.024876  False\n",
       "41  p015                    5       203                 0.024631  False\n",
       "42  p038                    3       122                 0.024590  False\n",
       "43  p033                   13       533                 0.024390  False\n",
       "44  p008                   10       419                 0.023866   True\n",
       "45  p066                    5       213                 0.023474  False\n",
       "46  p024                    6       259                 0.023166   True\n",
       "47  p002                    7       313                 0.022364  False\n",
       "48  p044                    5       226                 0.022124  False\n",
       "49  p013                    3       136                 0.022059  False\n",
       "50  p036                   17       772                 0.022021   True\n",
       "51  p030                    4       182                 0.021978  False\n",
       "52  p012                    6       278                 0.021583  False\n",
       "53  p005                    5       233                 0.021459  False\n",
       "54  p052                    4       187                 0.021390   True\n",
       "55  p070                    5       257                 0.019455  False\n",
       "56  p022                    4       212                 0.018868  False\n",
       "57  p040                    4       229                 0.017467  False\n",
       "58  p021                    3       177                 0.016949  False\n",
       "59  p043                    4       246                 0.016260  False\n",
       "60  p019                    3       227                 0.013216  False\n",
       "61  p014                    4       307                 0.013029  False\n",
       "62  p037                    3       240                 0.012500   True\n",
       "63  p004                    5       562                 0.008897  False\n",
       "64  p035                    3       351                 0.008547  False\n",
       "65  p064                    1       134                 0.007463  False\n",
       "66  p046                    1       241                 0.004149  False\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating ranking of papers where share of uncertain sentences is the highest\n",
    "\n",
    "uncertain_sentences_count = sentence_df.groupby('label').agg({'svc_wiki_prediction': 'sum',\n",
    "                                                              'sentence': 'count'}).reset_index()\n",
    "\n",
    "uncertain_sentences_count['uncertan_sentence_index'] = uncertain_sentences_count['svc_wiki_prediction']/uncertain_sentences_count['sentence']\n",
    "uncertain_sentences_count['cb'] = uncertain_sentences_count['label'].isin(cb)\n",
    "\n",
    "# Ranking of papers with highest fraction of uncertain sentences\n",
    "uncertain_sentences_count.sort_values('uncertan_sentence_index', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = uncertain_sentences_count.sort_values('uncertan_sentence_index', ascending=False).reset_index(drop=True)\n",
    "\n",
    "test[test.cb == False].reset_index().to_excel('sentence_uncertainity_score_ncb.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc_wiki_prediction</th>\n",
       "      <th>cb</th>\n",
       "      <th>sentence</th>\n",
       "      <th>no_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>12049</td>\n",
       "      <td>15.287825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4319</td>\n",
       "      <td>16.317898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>379</td>\n",
       "      <td>16.947230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>147</td>\n",
       "      <td>19.884354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   svc_wiki_prediction     cb  sentence   no_words\n",
       "0                    0  False     12049  15.287825\n",
       "1                    0   True      4319  16.317898\n",
       "2                    1  False       379  16.947230\n",
       "3                    1   True       147  19.884354"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arevage number of words in certain vs uncertain sentence\n",
    "sentence_df.groupby(['svc_wiki_prediction']).agg({'sentence': 'count',\n",
    "                                                  'no_words': 'mean'}).reset_index()\n",
    "\n",
    "# With CB split\n",
    "sentence_df.groupby(['svc_wiki_prediction', 'cb']).agg({'sentence': 'count',\n",
    "                                                   'no_words': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>svc_wiki_prediction</th>\n",
       "      <th>sentence</th>\n",
       "      <th>no_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p007</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>14.722892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p007</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>p026</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>16.446541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>p026</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>p032</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>18.429603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>p032</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>26.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>p034</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>12.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>p034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>p048</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>14.643443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>p048</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>p051</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>18.157407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>p051</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>p057</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>17.208092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>p057</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>p059</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>14.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>p059</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>p062</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>p062</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>p065</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>16.175595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>p065</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>p074</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>16.419753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>p074</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>15.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  svc_wiki_prediction  sentence   no_words\n",
       "10   p007                    0       166  14.722892\n",
       "11   p007                    1         9  21.000000\n",
       "46   p026                    0       159  16.446541\n",
       "47   p026                    1        15  19.400000\n",
       "56   p032                    0       277  18.429603\n",
       "57   p032                    1        25  26.880000\n",
       "60   p034                    0       171  12.807018\n",
       "61   p034                    1        10  14.200000\n",
       "88   p048                    0       244  14.643443\n",
       "89   p048                    1        16  15.625000\n",
       "90   p051                    0       108  18.157407\n",
       "91   p051                    1         6  21.333333\n",
       "100  p057                    0       173  17.208092\n",
       "101  p057                    1        10  13.500000\n",
       "104  p059                    0        75  14.160000\n",
       "105  p059                    1         5  17.400000\n",
       "108  p062                    0       244  14.000000\n",
       "109  p062                    1        15  19.533333\n",
       "114  p065                    0       336  16.175595\n",
       "115  p065                    1        19  20.526316\n",
       "132  p074                    0       324  16.419753\n",
       "133  p074                    1        20  15.050000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average number of words certain vs uncertain sentence per paper\n",
    "\n",
    "test = sentence_df.groupby(['label', 'svc_wiki_prediction']).agg({'sentence': 'count',\n",
    "                                                                  'no_words': 'mean'}).reset_index()\n",
    "\n",
    "# Top 10 articles with highest uncertain share\n",
    "test10 = test[test.label.isin(['p026', 'p032', 'p059', 'p048', 'p074', 'p062', 'p034', 'p057', 'p065', 'p051', 'p007'])]\n",
    "\n",
    "\n",
    "# Top articles with highest uncertain share have average number of words in unc = 18.586\n",
    "# and uncer = 15.74275851992153\n",
    "test10.loc[test10['svc_wiki_prediction'] == 0, 'no_words'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94      4094\n",
      "          1       0.98      0.68      0.81      1530\n",
      "\n",
      "avg / total       0.92      0.91      0.90      5624\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94      4094\n",
      "          1       0.99      0.67      0.80      1530\n",
      "\n",
      "avg / total       0.92      0.91      0.90      5624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating Random Forest vs SVM\n",
    "\n",
    "y = wiki_data['uncertanity_dummy']\n",
    "wiki_tfidf = tfidf.fit_transform(wiki_data['sentence'])\n",
    "x = wiki_tfidf\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 0, test_size=0.3)\n",
    "\n",
    "# Training random forest on wikipedia data\n",
    "rf_wiki = RandomForestClassifier(n_estimators=50, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "svc_wiki = SVC(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "# Predict uncertanity based on article data using RF\n",
    "rf_wiki_prediction = rf_wiki.predict(X_test)\n",
    "\n",
    "# Predict uncertanity based on article data using SVM\n",
    "svc_wiki_prediction = svc_wiki.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, rf_wiki_prediction))\n",
    "print(classification_report(y_test, svc_wiki_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8637517780938834"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRecision\n",
    "(0.91* 4094 + 0.74*1530)/5624\n",
    "\n",
    "# Recall\n",
    "#(0.98* 4094 + 0.62*1530)/5624\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4080</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  4080    14\n",
       "1   499  1031"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, rf_wiki_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4080</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  4080    14\n",
       "1   503  1027"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, svc_wiki_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
